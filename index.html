<h1>DECODING DIGITAL BORDERS</h1>

<h2>Introduction</h2>

<BODY>When the news broke that the British government had been deploying a racist algorithm in order to ratify visa applications, thereby discriminating against people from the Global South, the surprise was measured. 
Indeed, the happening fell within a long history of exclusionary migration policy, that has favoured a certain ideal, cosmopolitan type of ‘migrant’ in contrast to the economic, low-skilled migrant constructed as undeserving. Since the London attacks of 2005 the UK has increasingly securitised its borders in both a digital and analogue form.
This culminated in the "UK Home Office hostile environment policy" 2012, charged by the UNHCR as having "fostered xenophobia within the UK”.
Commonly, this was expressed in a hidden form, with policies exploiting structural identifiers. In 2015, in light of the migrant crisis, the UK introduced a points based system Since XXX the points based system has translated into an algorithm, hardening an already present bias and unquestioningly perpetuating the current politics of the UK government.
In light of this development, we consider an investigation into the specific workings of the algorithms to be paramount.
In the following we therefore specify the bias of the algorithm in question according to nationalities and document its perpetuating effect after its deployment, initially contextualizing the role of migration policy, algorithms and their intersection in UK governance. 
Against this qualitative, analytic background we will quantitatively evaluate the outcomes of visa applications to the UK, both before and after implementing the algorithm.</BODY>


<h2>Literature Review and approach</h2>

<BODY><p>Migration policies generally are intended to retain the integrity of a national political body (Asad, 2003; Mavelli, 2013), defining migrants as either deserving of legal status or not, in accordance to how they prop up the nation (Bosworth, 2008). In a European (Asad, 2003; Mavelli, 2013) and UK (Capdevila and Callaghan, 2008) context, migrants are therefore often considered to be either dangerous Others against with the nation defines itself, or an economically exploitable resource (with the exception of refugees), 
Thus, they are succumb to particularly harsh policies (Bove et al., 2021; Ceccorulli, 2019), which use migrants precarity for cheap labour, perpetuating global inequalities (de León, 2015; Garza, 2018; Mcc. Heyman, 1995). This occurs despite an interest in being meritocratic, rendering this approach crucial for understanding the broader ethics encoded in UK migration policy.</p>
 
<p>The use of statistically tools such as algorithms in policy have been documented to depoliticize and perpetuate these ethics, by switching the epistemology of government from a potentially political decision to an objective, calculated one (Amoore and Piotukh, 2015; Anders, 2008; Gilbert, 2020). Moreover, algorithms already have a long history of being unsuccessfully deployed at borders in different formats, however literature on algorithms in visa-decision processes remains sparse (Amoore, 2006; Anderson, 2014; Murphy and Maguire, 2015). 
Here, there is a great emphasis on how the presence of a ranking or predictive device (which can be an algorithm) are discriminatory, easily evaded, and ultimately inaccurate. The existence of a technologically securitized border still determines legality and shapes lives. Our investigation builds upon this work, approaching the perpetuative effect of the algorithm valuing visa decisions to the UK.</p>
 
<p>Algorithms already have a long history of being unsuccessfully deployed at borders, however in different formats (Amoore, 2006; Anderson, 2014; Murphy and Maguire, 2015). Here, there is a great emphasis on how the presence of a ranking or predictive device (which can be an algorithm) are discriminatory, easily evaded, and ultimately inaccurate. However the existence of a technologically securitized border still determines legality and shapes lives. This is not to say the deployment of algorithms in visa granting systems is inherently bad, indeed they are not the only black box present.
Government institutions retain an opacity and unpredictability, which is exacerbated due  to their inherent status of power (Mitchell, 2007; Tuckett, 2015). This may be actually rendered more tangible through an algorithm. It is from this nuanced perspective of critique and appreciation for the complex situation at hand, that we seek to decode the bias of the UK visa granting algorithm in an attempt to offer adequate solutions.</p>



  
<h2>Policy</h2>

<BODY> <p>Since 2015, the UK had filtered visa applications through an algorithm based on a traffic light system that assigned a red, amber or green risk level to each applicant. 
In 2017, a tech-justice group named FoxGlove launched a joint investigation with the Joint Council for the Welfare of Immigrants into the functioning of this system, claiming that it discriminated against certain nationalities.
They challenged the fact that the Home Office never revealed the details of its algorithm, and was able to keep its functioning a secret under Section 31st of the Freedom Information Act, which allows for the non-disclosure of information on immigration controls. 
In spite of this secrecy, the Home Office admitted that nationality was indeed a factor that helped to determine the allocation of applicants to a specific risk level. Once assigned by the algorithm, this rating by risk levels played a major role in shaping the outcome of the visa application. An applicant allocated to the ‘Red’ category because of their nationality could still be granted a visa.
However, their prospects of a successful application were much lower than the prospect of an otherwise equivalent individual with a different nationality allocated to the ‘Green’ category. To similar effect, the same ‘Red’ application was likely to take much longer.</p>
 
<p>Hence, people from mostly rich western countries were somehow getting “Speedy Boarding”, while poorer people of colour got pushed to the back of the queue because of their nationality.
According to the investigators, this seemed to portray an institutionally racist structure, picked up by the algorithm through a feedback loop or vicious cycle: visa decision rates prior to 2015 would be used to decide which countries were on the "suspect nationalities" list, and the algorithm would then use that list to classify a visa application under the “red risk level”.
Those biased results were then used to reinforce the “suspect nationalities” list, allegedly affecting African applicants at a stronger level.</p>
 
<p>FoxGlove and the JCWI asked for a judicial review of the Home Office’s algorithm, arguing that it violated the UK’s Equality Act of 2010.
The organization requested the public release of the details on the predictive mechanisms of the algorithm and the abandonment of the system. 
However, litigation is still ongoing. On August 7th 2020, British authorities announced that the algorithm would be abandoned, and a redesigned system would be put in place by October that same year. Despite this sudden decision, the Home Office still rejected the accusation of bias. 
Yet, authorities stated that they would keep such concerns in mind when designing both the interim and definite new systems, which would be focused on person-centric factors and would exclude nationality as a sorting criteria. Finally, the Home Office’s opaque policies and the lack of a judicial decision meant that our analysis could not rely on certain data: we knew that nationality played a role in the building of the risk scale, however the specific figures on the levels of green, yellow and red applications by nationality have not been released. 
Furthermore, the Home Office did not publish information on the resolution times for the applications of each scale, so we could not evaluate potential discrimination in this dimension. We were obliged to restrict our approach to the data published by British authorities.</p>
 
<p>Within this data, we were able to examine the different types of visa applications that the UK resorts to, depending on the visa type and on the different categories of applicants (which are partially built upon nationality).
Therefore, regarding visa types, our dataset contains twelve different categories. First, we find visitors, staying in the UK for a temporary period of less than six months. Second, sponsored study visas are meant for students who have been offered a place on a course by a licensed student sponsor. Non-sponsored study visas can also be granted. Skilled workers visas refer to a special category of visas among work visas, applied to those who have been offered a skilled job with a salary of at least £25,000.
The High Value visas follow the same logic but are meant for high-value individuals who will contribute to growth and productivity. The category of other work visas applies to those which do not fit in the skilled workers or high-value visas. Family visas allow people to apply upon their family connection with an individual who is either a UK citizen or has just been granted a visa. Temporary workers visas can be granted when someone needs to visit the UK for a short period of time to work. 
Other temporary visas are similar, but are meant for those who do not fit in the previous framework. Dependent visas may be granted to people who apply on the basis of their relationship with another applicant, whether they are joining or accompanying the latter. The EEA family permit allows non-EEA citizens to enter into the UK on the basis of their relationship with an EEA citizen. Lastly, the other settlement visas refer to visas that can allow for indefinite leave to enter (on arrival) or indefinite leave to remain (after entry).</p>
 
<p>Regarding applicant types, people can either apply as a main applicant or as a dependent. When applying as a dependent, they are not claiming their own rights but will be considered as part of the application of the main applicant because of their relation. The formalities of the visas may also vary depending on the State of citizenship of the applicant. Indeed, citizens of the EEA (EU + Norway, Iceland or Liechtenstein) and of Switzerland do not need to apply for a visa if they want to visit the UK for a short period of time (less than six months).</p> 

 
 <h2>Methodology</h2>
 
<img width="411" alt="Github 1" src="https://user-images.githubusercontent.com/92430113/145844706-f534e13b-eefe-40ee-b303-35e76b74a3cd.png">
 
<img width="606" alt="Github 2" src="https://user-images.githubusercontent.com/92430113/145984415-a3941b5d-c6c2-45f3-b881-1e7e0f763d49.png">
 
<img width="612" alt="Github 3" src="https://user-images.githubusercontent.com/92430113/145984577-8e98cab0-7dc3-4bf3-ba32-8c0f79d6548a.png">
 
<img width="615" alt="Github 4" src="https://user-images.githubusercontent.com/92430113/145985143-0c7afc90-7133-4210-a4c6-147782c7164a.png">

<img width="617" alt="Github 5" src="https://user-images.githubusercontent.com/92430113/145985156-e8bbe22b-d16c-470d-b21e-ba16322e4ca8.png">

<img width="607" alt="github 6" src="https://user-images.githubusercontent.com/92430113/145985226-ff8e274c-476f-4bfb-ab1c-b9cd8f7f52ce.png">

<img width="621" alt="Github 7" src="https://user-images.githubusercontent.com/92430113/145985240-65c2ad65-8bb5-4c5c-83a4-6cd92f5f64e6.png">

<img width="609" alt="Github 8" src="https://user-images.githubusercontent.com/92430113/145985389-51365722-78d5-488b-bf15-d4021e2a3f1a.png">

<img width="617" alt="Github 9" src="https://user-images.githubusercontent.com/92430113/145985267-d0d60d86-e433-47d8-a00f-c83b9dd0577a.png">

<img width="640" alt="Github 10" src="https://user-images.githubusercontent.com/92430113/145985325-dac27792-179d-4d65-9eb8-096ca92d00be.png">

  
<h2>Results</h2>

<h2>Scope and conclusions</h2>
