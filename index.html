<h1>DECODING DIGITAL BORDERS</h1>

<h2>Introduction</h2>

(<BODY>When the news broke that the British government had been deploying a racist algorithm in order to ratify visa applications, thereby discriminating against people from the Global South, the surprise was measured. 
Indeed, the happening fell within a long history of exclusionary migration policy, that has favoured a certain ideal, cosmopolitan type of ‘migrant’ in contrast to the economic, low-skilled migrant constructed as undeserving. Since the London attacks of 2005 the UK has increasingly securitised its borders in both a digital and analogue form.
This culminated in the "UK Home Office hostile environment policy" 2012, charged by the UNHCR as having "fostered xenophobia within the UK”.
Commonly, this was expressed in a hidden form, with policies exploiting structural identifiers. In 2015, in light of the migrant crisis, the UK introduced a points based system Since XXX the points based system has translated into an algorithm, hardening an already present bias and unquestioningly perpetuating the current politics of the UK government.
In light of this development, we consider an investigation into the specific workings of the algorithms to be paramount.
In the following we therefore specify the bias of the algorithm in question according to nationalities and document its perpetuating effect after its deployment, initially contextualizing the role of migration policy, algorithms and their intersection in UK governance. 
Against this qualitative, analytic background we will quantitatively evaluate the outcomes of visa applications to the UK, both before and after implementing the algorithm.</BODY>)*


<h2>Literature Review and approach</h2>

<h2>Policy</h2>

<h2>Methodology</h2>

<h2>Results</h2>

<h2>Scope and conclusions</h2>
