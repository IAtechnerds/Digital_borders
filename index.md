<h1>The biases of the UK visa issuing system : a qualitative and quantitative analysis</h1>

<h3> Final project - decoding biases in Artificial Intelligence - SciencesPo Paris 2021-2022</h3>
<h4>Group members</h4>
<BODY> GENELLETI.G, FLAMANT.M, MANGADA REAL DE ASUA.E, PAXTON.G, VIVENOT.B



<h2>Introduction</h2>

<BODY>When the news broke that the British government had been deploying a racist algorithm in order to ratify visa applications, thereby discriminating against people from the Global South, the surprise was measured. 
Indeed, the happening fell within a long history of exclusionary migration policy, that has favoured a certain ideal, cosmopolitan type of ‘migrant’ in contrast to the economic, low-skilled migrant constructed as undeserving. Since the London attacks of 2005 the UK has increasingly securitised its borders in both a digital and analogue form.
This culminated in the "UK Home Office hostile environment policy" 2012, charged by the UNHCR as having "fostered xenophobia within the UK”.
Commonly, this was expressed in a hidden form, with policies exploiting structural identifiers. In 2015, in light of the migrant crisis, the UK introduced a points based system Since XXX the points based system has translated into an algorithm, hardening an already present bias and unquestioningly perpetuating the current politics of the UK government.
In light of this development, we consider an investigation into the specific workings of the algorithms to be paramount.
In the following we therefore specify the bias of the algorithm in question according to nationalities and document its perpetuating effect after its deployment, initially contextualizing the role of migration policy, algorithms and their intersection in UK governance. 
Against this qualitative, analytic background we will quantitatively evaluate the outcomes of visa applications to the UK, both before and after implementing the algorithm.</BODY>


<h2>Literature Review and approach</h2>

<BODY><p>Migration policies generally are intended to retain the integrity of a national political body (Asad, 2003; Mavelli, 2013), defining migrants as either deserving of legal status or not, in accordance to how they prop up the nation (Bosworth, 2008). In a European (Asad, 2003; Mavelli, 2013) and UK (Capdevila and Callaghan, 2008) context, migrants are therefore often considered to be either dangerous Others against with the nation defines itself, or an economically exploitable resource (with the exception of refugees), 
Thus, they are succumb to particularly harsh policies (Bove et al., 2021; Ceccorulli, 2019), which use migrants precarity for cheap labour, perpetuating global inequalities (de León, 2015; Garza, 2018; Mcc. Heyman, 1995). This occurs despite an interest in being meritocratic, rendering this approach crucial for understanding the broader ethics encoded in UK migration policy.</p>
 
<p>The use of statistically tools such as algorithms in policy have been documented to depoliticize and perpetuate these ethics, by switching the epistemology of government from a potentially political decision to an objective, calculated one (Amoore and Piotukh, 2015; Anders, 2008; Gilbert, 2020). Moreover, algorithms already have a long history of being unsuccessfully deployed at borders in different formats, however literature on algorithms in visa-decision processes remains sparse (Amoore, 2006; Anderson, 2014; Murphy and Maguire, 2015). 
Here, there is a great emphasis on how the presence of a ranking or predictive device (which can be an algorithm) are discriminatory, easily evaded, and ultimately inaccurate. The existence of a technologically securitized border still determines legality and shapes lives. Our investigation builds upon this work, approaching the perpetuative effect of the algorithm valuing visa decisions to the UK.</p>
 
<p>Algorithms already have a long history of being unsuccessfully deployed at borders, however in different formats (Amoore, 2006; Anderson, 2014; Murphy and Maguire, 2015). Here, there is a great emphasis on how the presence of a ranking or predictive device (which can be an algorithm) are discriminatory, easily evaded, and ultimately inaccurate. However the existence of a technologically securitized border still determines legality and shapes lives. This is not to say the deployment of algorithms in visa granting systems is inherently bad, indeed they are not the only black box present.
Government institutions retain an opacity and unpredictability, which is exacerbated due  to their inherent status of power (Mitchell, 2007; Tuckett, 2015). This may be actually rendered more tangible through an algorithm. It is from this nuanced perspective of critique and appreciation for the complex situation at hand, that we seek to decode the bias of the UK visa granting algorithm in an attempt to offer adequate solutions.</p>



  
<h2>Policy development and algorithm's dployment</h2>

<BODY> <p>Since 2015, the UK had filtered visa applications through an algorithm based on a traffic light system that assigned a red, amber or green risk level to each applicant. 
In 2017, a tech-justice group named FoxGlove launched a joint investigation with the Joint Council for the Welfare of Immigrants into the functioning of this system, claiming that it discriminated against certain nationalities.
They challenged the fact that the Home Office never revealed the details of its algorithm, and was able to keep its functioning a secret under Section 31st of the Freedom Information Act, which allows for the non-disclosure of information on immigration controls. 
In spite of this secrecy, the Home Office admitted that nationality was indeed a factor that helped to determine the allocation of applicants to a specific risk level. Once assigned by the algorithm, this rating by risk levels played a major role in shaping the outcome of the visa application. An applicant allocated to the ‘Red’ category because of their nationality could still be granted a visa.
However, their prospects of a successful application were much lower than the prospect of an otherwise equivalent individual with a different nationality allocated to the ‘Green’ category. To similar effect, the same ‘Red’ application was likely to take much longer.</p>
 
<p>Hence, people from mostly rich western countries were somehow getting “Speedy Boarding”, while poorer people of colour got pushed to the back of the queue because of their nationality.
According to the investigators, this seemed to portray an institutionally racist structure, picked up by the algorithm through a feedback loop or vicious cycle: visa decision rates prior to 2015 would be used to decide which countries were on the "suspect nationalities" list, and the algorithm would then use that list to classify a visa application under the “red risk level”.
Those biased results were then used to reinforce the “suspect nationalities” list, allegedly affecting African applicants at a stronger level.</p>
 
<p>FoxGlove and the JCWI asked for a judicial review of the Home Office’s algorithm, arguing that it violated the UK’s Equality Act of 2010.
The organization requested the public release of the details on the predictive mechanisms of the algorithm and the abandonment of the system. 
However, litigation is still ongoing. On August 7th 2020, British authorities announced that the algorithm would be abandoned, and a redesigned system would be put in place by October that same year. Despite this sudden decision, the Home Office still rejected the accusation of bias. 
Yet, authorities stated that they would keep such concerns in mind when designing both the interim and definite new systems, which would be focused on person-centric factors and would exclude nationality as a sorting criteria. Finally, the Home Office’s opaque policies and the lack of a judicial decision meant that our analysis could not rely on certain data: we knew that nationality played a role in the building of the risk scale, however the specific figures on the levels of green, yellow and red applications by nationality have not been released. 
Furthermore, the Home Office did not publish information on the resolution times for the applications of each scale, so we could not evaluate potential discrimination in this dimension. We were obliged to restrict our approach to the data published by British authorities.</p>
 
<p>Within this data, we were able to examine the different types of visa applications that the UK resorts to, depending on the visa type and on the different categories of applicants (which are partially built upon nationality).
Therefore, regarding visa types, our dataset contains twelve different categories. First, we find visitors, staying in the UK for a temporary period of less than six months. Second, sponsored study visas are meant for students who have been offered a place on a course by a licensed student sponsor. Non-sponsored study visas can also be granted. Skilled workers visas refer to a special category of visas among work visas, applied to those who have been offered a skilled job with a salary of at least £25,000.
The High Value visas follow the same logic but are meant for high-value individuals who will contribute to growth and productivity. The category of other work visas applies to those which do not fit in the skilled workers or high-value visas. Family visas allow people to apply upon their family connection with an individual who is either a UK citizen or has just been granted a visa. Temporary workers visas can be granted when someone needs to visit the UK for a short period of time to work. 
Other temporary visas are similar, but are meant for those who do not fit in the previous framework. Dependent visas may be granted to people who apply on the basis of their relationship with another applicant, whether they are joining or accompanying the latter. The EEA family permit allows non-EEA citizens to enter into the UK on the basis of their relationship with an EEA citizen. Lastly, the other settlement visas refer to visas that can allow for indefinite leave to enter (on arrival) or indefinite leave to remain (after entry).</p>
 
<p>Regarding applicant types, people can either apply as a main applicant or as a dependent. When applying as a dependent, they are not claiming their own rights but will be considered as part of the application of the main applicant because of their relation. The formalities of the visas may also vary depending on the State of citizenship of the applicant. Indeed, citizens of the EEA (EU + Norway, Iceland or Liechtenstein) and of Switzerland do not need to apply for a visa if they want to visit the UK for a short period of time (less than six months).</p> 

 
 <h2>Methodology</h2>
 
 
 
<img width="411" alt="Github 1" src="https://user-images.githubusercontent.com/92430113/145844706-f534e13b-eefe-40ee-b303-35e76b74a3cd.png">
 
<img width="606" alt="Github 2" src="https://user-images.githubusercontent.com/92430113/145984415-a3941b5d-c6c2-45f3-b881-1e7e0f763d49.png">
 
<img width="615" alt="Github 4" src="https://user-images.githubusercontent.com/92430113/145985143-0c7afc90-7133-4210-a4c6-147782c7164a.png">

<img width="617" alt="Github 5" src="https://user-images.githubusercontent.com/92430113/145985156-e8bbe22b-d16c-470d-b21e-ba16322e4ca8.png">

<img width="607" alt="github 6" src="https://user-images.githubusercontent.com/92430113/145985226-ff8e274c-476f-4bfb-ab1c-b9cd8f7f52ce.png">

<img width="621" alt="Github 7" src="https://user-images.githubusercontent.com/92430113/145985240-65c2ad65-8bb5-4c5c-83a4-6cd92f5f64e6.png">

<img width="609" alt="Github 8" src="https://user-images.githubusercontent.com/92430113/145985389-51365722-78d5-488b-bf15-d4021e2a3f1a.png">

<img width="617" alt="Github 9" src="https://user-images.githubusercontent.com/92430113/145985267-d0d60d86-e433-47d8-a00f-c83b9dd0577a.png">

<img width="640" alt="Github 10" src="https://user-images.githubusercontent.com/92430113/145985325-dac27792-179d-4d65-9eb8-096ca92d00be.png">

  
<h2>Results</h2>

<h2>Scope and conclusions</h2>
 
It is therefore evident from our analysis that the algorithm deployed by the UK Home office perpetuated existent racist dynamics further. More concretely, nationality played a role in informing the risk scores used to classify applicants. Our analysis shows that as a result,  the UK Visa Issuing Algorithm negatively affected North African applicants more than other applicants. Indeed, North African visa applicants were disproportionately rejected before 2015. However, this increased with the introduction of the algorithm which furthered this effect, potentially both in form or through the presence of an internal feedback loop. Nevertheless, contrary to what was initially alleged, the bias did not seem to discriminate against Sub-Saharan African applicants.

Probing further, the Visa Types that were most affected by a decrease of the Visa Issue Rate in North Africa before and after 2015 were those linked to a higher level of vulnerability and need of [humanitarian] assistance, whilst a tendency that was more broadly identifiable. Moreover, the Applicant Type that was most affected by a decrease of the Visa Issue Rate in North Africa before and after 2015 was the Dependent type. Both these findings further emphasise the prioritization of economic profitability in disregard for the potential sociality ensuing migration, long since an exploitative cornerstone of migration policy.  The question remains, considering the algorithm is a perpetuation of exclusionary dynamics of the nation-state beyond a reiteration of biases in data, what a fair and realistic deployment of algorithms at borders would look like. In other words an algorithm which genuinely addresses contemporary socio-economic tensions, to political and real world effect.
 
 
<h2>Bibliography</h2>
 
Amoore, L., 2006. Biometric borders: Governing mobilities in the war on terror. Political Geography 25, 336–351. https://doi.org/10.1016/j.polgeo.2006.02.001

Amoore, L., Piotukh, V., 2015. Life Beyond Big Data: Governing with Little Analytics. Economy and Society 44, 341–366. https://doi.org/10.1080/03085147.2015.1043793

Anders, G., 2008. The Normativity of Numbers: World bank and IMF Conditionality. Political and Legal Anthropology Review 31, 187–202. https://doi.org/10.1111/j.1555-2934.2008.00021.x

Anderson, R., 2014. Illegality, Inc.: Clandestine Migration and the Business of Bordering Europe. University of California Press. https://doi.org/10.1093/he/9780199601660.003.0011

Asad, T., 2003. What Might an Anthropology of Secularism Look Like?, in: Formations of the Secular: Christianity, Islam, Modernity. Stanford University Press, Stanford, California, pp. 21–66.

Bosworth, M., 2008. Border control and the limits of the Sovereign State. Social and Legal Studies 17, 199–215. https://doi.org/10.1177/0964663908089611

Bove, V., Böhmelt, T., Nussio, E., 2021. Terrorism Abroad and Migration Policies at Home. Journal of European Public Policy 28, 190–207. https://doi.org/10.1080/13501763.2020.1729227

Capdevila, R., Callaghan, J.E.M., 2008. ‘It’s not Racist. It’s Common Sense’. A Critical Analysis of Political Discourse Around Asylum and Immigration in the UK. Journal of Community and Applied Social Psychology 1–16. https://doi.org/10.1002/casp

Ceccorulli, M., 2019. Back to Schengen: the collective securitisation of the EU free-border area. West European Politics 42, 302–322. https://doi.org/10.1080/01402382.2018.1510196

Bulman, M. (2019, June 5). Austerity measures and hostile environment ‘entrenching racism’ in UK, says UN. The Independent. https://www.independent.co.uk/news/uk/home-news/austerity-racism-hostile-environment-xenophobia-un-report-rapporteur-immigration-bame-a8959866.html

de León, J., 2015. The Land of Open Graves: Living and Dying on the Migrant Trail, City & Society. University of California Press, Oakland, California.

Garza, A.G., 2018. The temporality of illegality. Focaal 2018, 86–98. https://doi.org/10.3167/fcl.2018.810107

Gilbert, P.R., 2020. Speculating on sovereignty: ‘money mining’ and corporate foreign policy at the extractive industry frontier. Economy and Society 49, 16–44. https://doi.org/10.1080/03085147.2019.1690255

GOV.UK. (2021a). Browse: Work in the UK. https://www.gov.uk/browse/visas-immigration/work-visas

GOV.UK. (2021b). Managed migration datasets. https://www.gov.uk/government/statistical-data-sets/managed-migration-datasets

Heaven, W. D. (2020, August 5). The UK is dropping an immigration algorithm that critics say is racist. MIT Technology Review. https://www.technologyreview.com/2020/08/05/1006034/the-uk-is-dropping-an-immigration-algorithm-that-critics-say-is-racist/

HM Government, 2020. The UK’s Points-Based Immigration System: Further Details.
Home Office says it will abandon its racist visa algorithm – after we sued them. (2020, August 4). Foxglove. https://www.foxglove.org.uk/2020/08/04/home-office-says-it-will-abandon-its-racist-visa-algorithm-after-we-sued-them/

Lomas, N. (2020, August 4). UK commits to redesign visa streaming algorithm after challenge to “racist” tool. TechCrunch. https://techcrunch.com/2020/08/04/uk-commits-to-redesign-visa-streaming-algorithm-after-challenge-to-racist-tool/?guccounter=1

Mavelli, L., 2013. Between Normalisation and Exception: The Securitisation of Islam and the Construction of the Secular Subject. Millennium: Journal of International Studies 41, 159–181. https://doi.org/10.1177/0305829812463655

Mcc. Heyman, J., 1995. Putting Power in the Anthropology of Bureaucracy: The Immigration and Naturalization Service at the Mexico-United States Border. Current Anthropology 36, 261–287. https://doi.org/10.1086/204354

McDonald, H. (2020, August 4). Home Office to scrap “racist algorithm” for UK visa applicants. The Guardian. https://www.theguardian.com/uk-news/2020/aug/04/home-office-to-scrap-racist-algorithm-for-uk-visa-applicants

Mitchell, T., 2007. Society, Economy, and the State Effect, in: Sharma, A., Gupta, A. (Eds.), The Anthropology of the State: A Reader. Blackwell Publishing Ltd., pp. 172–186.

Murphy, E., Maguire, M., 2015. Speed, Time and Security: Anthropological Perspectives on Automated Border Control. Etnofoor 27, 157–177.

Tuckett, A., 2015. Strategies of Navigation: Migrants’ Everyday Encounters with Italian Immigration Bureaucracy. The Cambridge Journal of Anthropology 33, 113–128. https://doi.org/10.3167/ca.2015.330109

Warrel, H. (2020, August 4). Home Office drops ‘biased’ visa algorithm. Financial Times. https://www.ft.com/content/a02c6c42-95b1-419c-a798-0418011d2018

We won! Home Office to stop using racist visa algorithm. (2020). The Joint Council for the Welfare of Immigrants. https://www.jcwi.org.uk/News/we-won-home-office-to-stop-using-racist-visa-algorithm


