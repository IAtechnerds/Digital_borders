<h1>The biases of the UK visa issuing system : a qualitative and quantitative analysis</h1>

<h2> Final project - decoding biases in Artificial Intelligence - SciencesPo Paris 2021-2022</h2>

<h3>Group members</h3>
<BODY> FLAMANT.M, GENELETTI.G, MANGADA REAL DE ASUA.E, PAXTON.G, VIVENOT.B

 <h3>Table of content</h3>
 
<ol>
 <li>Introduction</li>
 <li>Literature review and approach</li>
 <li>Policy development and algorithm's deployment</li>
 <li>Methodology</li>
 <li>Scope and conclusions</li>
 <li>Bibliography</li>
 </ol>

<h2>Introduction</h2>

<BODY><p align="justify">When the news broke that the British government had been deploying a racist algorithm in order to ratify visa applications, thereby discriminating against people from the Global South, the surprise was measured. Indeed, the happening fell within a long history of exclusionary migration policy, that has favoured a certain ideal, cosmopolitan type of ‘migrant’ in contrast to the economic, low-skilled migrant constructed as undeserving. Since the London attacks of 2005 the UK has increasingly securitised its borders in both a digital and analogue form. This culminated in the "UK Home Office hostile environment policy" of 2012, charged by the UNHCR as having "fostered xenophobia within the UK” (Bulman, 2019). Commonly, this was expressed in a hidden form, with policies exploiting structural identifiers. In 2015, in light of the migrant crisis, the UK introduced a points based system (HM Government, 2020) that translated into an algorithm, hardening an already present bias and unquestioningly perpetuating the current politics of the UK government. In light of this development, we consider an investigation into the specific workings of the algorithms to be paramount. In the following, we therefore specify the bias of the algorithm in question according to nationalities and document its perpetuating effect after its deployment, initially contextualizing the role of migration policy, algorithms and their intersection in UK governance. Against this qualitative, analytic background we will quantitatively evaluate the outcomes of visa applications to the UK, both before and after implementing the algorithm.</p></BODY>


<h2>Literature Review and Approach</h2>

<BODY><p align="justify">Migration policies are generally intended to retain the integrity of a national political body (Asad, 2003; Mavelli, 2013), defining migrants as either deserving of legal status or not, in accordance to how they prop up the nation (Bosworth, 2008). In a European (Asad, 2003; Mavelli, 2013) and UK (Capdevila and Callaghan, 2008) context, migrants are therefore often considered to be either dangerous “Others” against which the nation defines itself, or an economically exploitable resource (with the exception of refugees). Thus, they succumb to particularly harsh policies (Bove et al., 2021; Ceccorulli, 2019), which use migrants’ precarity for cheap labour, perpetuating global inequalities (de León, 2015; Garza, 2018; Mcc. Heyman, 1995). This occurs despite an interest in being meritocratic, rendering this approach crucial for understanding the broader ethics encoded in UK migration policy.</p>
 
<p align="justify">The use of statistical tools such as algorithms in policy has been documented to depoliticize and perpetuate these ethics, by switching the epistemology of government from a potentially political decision to an objective, calculated one (Amoore and Piotukh, 2015; Anders, 2008; Gilbert, 2020). Moreover, algorithms already have a long history of being unsuccessfully deployed at borders in different formats, however literature on algorithms in visa-decision processes remains sparse (Amoore, 2006; Anderson, 2014; Murphy and Maguire, 2015). Here, there is a great emphasis on how the presence of a ranking or predictive device (which can be an algorithm) are discriminatory, easily evaded, and ultimately inaccurate. The existence of a technologically securitized border still determines legality and shapes lives. Our investigation builds upon this work, approaching the perpetuative effect of the algorithm valuing visa decisions to the UK. This is not to say the deployment of algorithms in visa granting systems is inherently bad, indeed they are not the only black box present. Government institutions retain an opacity and unpredictability, which is exacerbated due to their inherent status of power (Mitchell, 2007; Tuckett, 2015). This may be actually rendered more tangible through an algorithm. It is from this nuanced perspective of critique and appreciation for the complex situation at hand, that we seek to decode the bias of the UK visa granting algorithm in an attempt to offer adequate solutions.</p>

 
<h2>Policy Development and Algorithm's Deployment</h2>

<BODY> <p align="justify">The dynamics outlined above have indeed been observed in the UK immigration system. Since 2015, the UK has filtered visa applications through an algorithm based on a traffic light system that assigned a red, amber or green risk level to each applicant. A joint investigation in 2017 between the tech-justice group FoxGlove (2020) and the Joint Council for the Welfare of Immigrants (2020) claimed that it discriminated against certain nationalities. The precise functioning of the algorithm had never been released by the Home Office as under Section 31st of the Freedom Information Act  information on immigration controls does not have to be disclosed. Despite this, following investigation the Home Office admitted that nationality was indeed a factor that partly determined the allocation of applicants to a specific risk level, thus playing a major role in shaping the outcome of a visa application. Assignment to the ‘red’ category greatly reduced both the prior prospects of a successful application and significantly increased the duration of the visa processing. According to the investigation, this portrayed an institutionally racist structure, which had been extended by the algorithm as it used visa decision rates prior to 2015 would be used to decide which nationalities would be linked to higher (red) risk levels. This allegedly negatively affected African applicants (See also: McDonald, 2020; Lomas, 2020; Warrel, 2020; Heaven, 2020).</p>
 
<p align="justify">FoxGlove and the JCWI requested a judicial review of the Home Office’s algorithm, arguing that it violated the UK’s Equality Act of 2010. They requested the public release of the details of the predictive mechanisms and the abandonment of the system. However, litigation is still ongoing. On August 4th 2020, British authorities announced that the algorithm would be abandoned, and a redesigned system would be put in place by October of the same year. The Home Office thereby still rejected the accusation of a racial bias, however assured the public that such concerns would be considered when designing both the interim and definite new systems, focusing them on person-centric factors, excluding nationality as a sorting criteria. Today, the functioning and the predictive features of this definite new system remain undisclosed, and there is no available data on the impacts that it is having on the processing and outcomes of visa applications. As such, the UK government has been exploiting the legal ambiguity of both not acknowledging an ingrained racial bias, as well as pledging to change in order to not disclose the precise workings of the algorithm aiding the visa decision process. However, the UK government was obliged to release certain data on past visa decisions (GOV.UK, 2021b). We make use of the available data in order to approximate the workings of the algorithm, which were never disclosed, nearing a more comprehensive understanding of the synergies between algorithms and migration policy.</p>
 
 <h2>Methodology</h2>
 
<p align="justify">Due to the Home Office’s opaque policies and the lack of a judicial decision, our quantitative analysis <strong>could not rely on certain data</strong>. Namely, whilst aware that nationality was relevant to the risk scale, the specific risk-scales attributed to applicants remained unreleased. Furthermore, the Home Office <stong>did not publish information on the resolution times</strong> of applications, inhibiting us form evaluating potential discrimination in this dimension. However, we were able to analyse the <strong>different visa types that constitute UK migration policy as well as the categories of applicants</strong> that apply to the various visa types. Due to global socio-economic structures (outlined in the literature review) these visa types and applicant categories can be linked to nationalities. Therefore, our quantitative approach utilizes the existence of differentiations in the categorization of visa applications, according to the education level, family and working status, and personal ties of the applicants. We subsequently build upon this, using the politicization of international relations in order to reflect on the racist effects of the algorithm. As such this analysis is built on three main blocks: (A) first, an analysis on the origin of the applicants by region and nationality, which in itself is divided into three sub-analyses (1, 2 and 3); (B) second, an analysis on visa types for all regions; and (C) third, an analysis on applicant types for all regions.<p>
 
 <h3>A. Analysis on the origin of the applicant (region and nationality)</h3>
 
 <p align="justify">Regarding the bias that was already recognized as such, the origin of the applicants (region and nationality), we find that the lowests percentages of visa issue rate come from countries in Africa, as shown in the graph below.</p>
 <img width="606" alt="Github 2" src="https://user-images.githubusercontent.com/92430113/145984415-a3941b5d-c6c2-45f3-b881-1e7e0f763d49.png">
 
 <p align="justify">From here on, our analysis focused on the clustering in <strong>two time spans</strong>. The first, <strong>2005-2014</strong> corresponds to the time before the alleged discriminatory algorithm existed and the second, <strong>2015-2020</strong> to when this algorithm was used. Comparison of these two times spans allows us to draw conclusions on whether the second system was indeed discriminatory or not. As it can be read in the graph below, we find that the region that saw the biggest change between the two periods is North Africa.</p>

 <img width="615" alt="Github 4" src="https://user-images.githubusercontent.com/92430113/145985143-0c7afc90-7133-4210-a4c6-147782c7164a.png">
 
 <p align="justify">Following this, we focus our analysis on North Africa, still comparing the data from 2005-2014 to 2015-2020. We proceed in three steps: (1) by analysing the visa issue rate per country; (2) then the visa issue rate per country; and (3) lastly the visa issue rate per applicant type.</p>
 
 <h4>1) Analysis of visa issue rate per country</h4>
 
 <p align="justify">Here, our analysis shows that the percentage of visa issued lowers significantly from the data before and after the algorithm was introduced. This finding allows us to <strong>confirm the bias of the algorithm towards North African applicants</strong>. Such a bias must be read in light of the migrant crisis of 2015. Indeed, political and terrorist troubles in North Africa forced people to leave their home country (particularly Tunisia and Libya) and to go to Europe. As a result, the UK adopted a more protectionist visa issuance policy.</p>
 
<img width="617" alt="Github 5" src="https://user-images.githubusercontent.com/92430113/145985156-e8bbe22b-d16c-470d-b21e-ba16322e4ca8.png">
 
 <h4>2) Analysis of visa issue rate per visa type</h4>
 
<p align="justify">This analysis shows that the visa types issuance rate that lower the most are the EEA family permit, the Family, the visitors, the high value and the other study. The <strong>EEA family permit</strong> allows non-EEA citizens to enter into the UK on the basis of their relationship with an EEA citizen. <strong>Family visas</strong> allow people to apply upon their family connection with an individual who is either a UK citizen or has just been granted a visa. <strong>Visitor visas</strong> allow successful applicants to stay in the UK for a temporary period of less than six months. The <strong>High Value visas</strong> are designed for highly skilled workers who (among other restrictive requirements) have an annual salary higher than £25,000 (which is the basic requirement for being considered under the Skilled Worker category).</p>
 
<img width="607" alt="github 6" src="https://user-images.githubusercontent.com/92430113/145985226-ff8e274c-476f-4bfb-ab1c-b9cd8f7f52ce.png">
 
 <h4>3) Analysis of visa issuance rate per applicant type</h4>
 
<p align="justify">In this part, we analysed the visa issuance rate per applicant type for North Africa, with the data still divided in the two time spans mentioned above. As a “dependent”, applicants are not claiming their own rights but will be considered as part of the application of the main applicant because of their relation. We observe that <strong>the category of dependents is the one that lowered the most</strong>. This does not allow us to draw absolute conclusions. We can make the assumption that, because dependents are very often children accompanying their parents, a decrease in the visa issuance rate for them demonstrates the UK’s intention to limit migration.</p>

<img width="621" alt="Github 7" src="https://user-images.githubusercontent.com/92430113/145985240-65c2ad65-8bb5-4c5c-83a4-6cd92f5f64e6.png">
 
 <h3>B. Analysis on visa type (for all regions)</h3>
 
<p>In this second part, we analysed potential discrimination on the Visa Type, not applied to specific Regions or nationalities.</p>
 
<img width="609" alt="Github 8" src="https://user-images.githubusercontent.com/92430113/145985389-51365722-78d5-488b-bf15-d4021e2a3f1a.png">
 
<p align="justify">As we did in our previous analysis, we have clustered our analysis of the visa types in two time spans: for the years 2005-2014 and 2015-2020. We observe that the percentages of the visa issuance rate for visa type that lowers the most are the <strong>EEA family permit and the other settlements</strong>. The latter refers to visas that can allow for indefinite leave to enter (on arrival) or indefinite leave to remain (after entry). These results, shown in the graph below, are quite telling in showing how the UK was willing to issue visas to migrants who would “prop up the nation'' (Bosworth, 2008). Indeed, the visa issuance rate for <strong>skilled workers, temporary workers</strong> (those granted to people with lower wages and more precarious, seasonal and therefore short-term jobs) <strong>and other study</strong> increased while these rates decreased significantly for EEA family permits and other settlements, the latter categories involving no consideration of the professional or academic qualification of the applicants.</p>

<img width="617" alt="Github 9" src="https://user-images.githubusercontent.com/92430113/145985267-d0d60d86-e433-47d8-a00f-c83b9dd0577a.png">

<img width="640" alt="Github 10" src="https://user-images.githubusercontent.com/92430113/145985325-dac27792-179d-4d65-9eb8-096ca92d00be.png">

 
 <h3>C. Analysis on applicant type (for all regions)</h3>
 
<p align="justify">In this third part, we follow an analysis of the Applicant Visa Issue Rate for all the years, thus without time clustering. Out of our three studies, this quantitative analysis block shows the least relevant results: the applicant type does not seem to show a strong impact on the visa issue rates. Therefore, our study cannot draw any relevant conclusions from this analysis. These inconclusive results do not change when clustering by time (2005-2014 and 2015-2020), as seen in the following graph.</p> 
 
<img width="622" alt="github 11" src="https://user-images.githubusercontent.com/92430113/146191838-94786c95-f004-4ce4-8d79-2c3b4721b081.png">

<h2>Scope and conclusions</h2>
 
<p align="justify">It is therefore evident from our analysis that the algorithm deployed by the UK Home office perpetuated existent racist dynamics further. More concretely, nationality played a role in informing the risk scores used to classify applicants. Our analysis shows that as a result,  the UK Visa Issuing Algorithm negatively affected North African applicants more than other applicants. Indeed, North African visa applicants were disproportionately rejected before 2015. However, this increased with the introduction of the algorithm which furthered this effect, potentially both in form or through the presence of an internal feedback loop. Nevertheless, contrary to what was initially alleged, the bias did not seem to discriminate against Sub-Saharan African applicants.</p>

<p align="justify">Probing further, the Visa Types that were most affected by a decrease of the Visa Issue Rate in North Africa before and after 2015 were those linked to a higher level of vulnerability and need of [humanitarian] assistance, whilst a tendency that was more broadly identifiable. Moreover, the Applicant Type that was most affected by a decrease of the Visa Issue Rate in North Africa before and after 2015 was the Dependent type. Both these findings further emphasise the prioritization of economic profitability in disregard for the potential sociality ensuing migration, long since an exploitative cornerstone of migration policy.  The question remains, considering the algorithm is a perpetuation of exclusionary dynamics of the nation-state beyond a reiteration of biases in data, what a fair and realistic deployment of algorithms at borders would look like. In other words an algorithm which genuinely addresses contemporary socio-economic tensions, to political and real world effect.</p>
 
<h2>Bibliography</h2>
 
<p>Amoore, L., 2006. Biometric borders: Governing mobilities in the war on terror. Political Geography 25, 336–351. https://doi.org/10.1016/j.polgeo.2006.02.001</p>

<p>Amoore, L., Piotukh, V., 2015. Life Beyond Big Data: Governing with Little Analytics. Economy and Society 44, 341–366. https://doi.org/10.1080/03085147.2015.1043793</p>

<p>Anders, G., 2008. The Normativity of Numbers: World bank and IMF Conditionality. Political and Legal Anthropology Review 31, 187–202. https://doi.org/10.1111/j.1555-2934.2008.00021.x</p>

<p>Anderson, R., 2014. Illegality, Inc.: Clandestine Migration and the Business of Bordering Europe. University of California Press. https://doi.org/10.1093/he/9780199601660.003.0011</p>

<p>Asad, T., 2003. What Might an Anthropology of Secularism Look Like?, in: Formations of the Secular: Christianity, Islam, Modernity. Stanford University Press, Stanford, California, pp. 21–66.</p>

<p>Bosworth, M., 2008. Border control and the limits of the Sovereign State. Social and Legal Studies 17, 199–215. https://doi.org/10.1177/0964663908089611</p>

<p>Bove, V., Böhmelt, T., Nussio, E., 2021. Terrorism Abroad and Migration Policies at Home. Journal of European Public Policy 28, 190–207. https://doi.org/10.1080/13501763.2020.1729227</p>

<p>Capdevila, R., Callaghan, J.E.M., 2008. ‘It’s not Racist. It’s Common Sense’. A Critical Analysis of Political Discourse Around Asylum and Immigration in the UK. Journal of Community and Applied Social Psychology 1–16. https://doi.org/10.1002/casp</p>

<p>Ceccorulli, M., 2019. Back to Schengen: the collective securitisation of the EU free-border area. West European Politics 42, 302–322. https://doi.org/10.1080/01402382.2018.1510196</p>

<p>Bulman, M. (2019, June 5). Austerity measures and hostile environment ‘entrenching racism’ in UK, says UN. The Independent. https://www.independent.co.uk/news/uk/home-news/austerity-racism-hostile-environment-xenophobia-un-report-rapporteur-immigration-bame-a8959866.html</p>

<p>De León, J., 2015. The Land of Open Graves: Living and Dying on the Migrant Trail, City & Society. University of California Press, Oakland, California.</p>

<p>Garza, A.G., 2018. The temporality of illegality. Focaal 2018, 86–98. https://doi.org/10.3167/fcl.2018.810107</p>

<p>Gilbert, P.R., 2020. Speculating on sovereignty: ‘money mining’ and corporate foreign policy at the extractive industry frontier. Economy and Society 49, 16–44. https://doi.org/10.1080/03085147.2019.1690255</p>

<p>GOV.UK. (2021a). Browse: Work in the UK. https://www.gov.uk/browse/visas-immigration/work-visas</p>

<p>GOV.UK. (2021b). Managed migration datasets. https://www.gov.uk/government/statistical-data-sets/managed-migration-datasets</p>

<p>Heaven, W. D. (2020, August 5). The UK is dropping an immigration algorithm that critics say is racist. MIT Technology Review. https://www.technologyreview.com/2020/08/05/1006034/the-uk-is-dropping-an-immigration-algorithm-that-critics-say-is-racist/</p>

<p>HM Government, 2020. The UK’s Points-Based Immigration System: Further Details.
Home Office says it will abandon its racist visa algorithm – after we sued them. (2020, August 4). Foxglove. https://www.foxglove.org.uk/2020/08/04/home-office-says-it-will-abandon-its-racist-visa-algorithm-after-we-sued-them/</p>

<p>Lomas, N. (2020, August 4). UK commits to redesign visa streaming algorithm after challenge to “racist” tool. TechCrunch. https://techcrunch.com/2020/08/04/uk-commits-to-redesign-visa-streaming-algorithm-after-challenge-to-racist-tool/?guccounter=1</p>

<p>Mavelli, L., 2013. Between Normalisation and Exception: The Securitisation of Islam and the Construction of the Secular Subject. Millennium: Journal of International Studies 41, 159–181. https://doi.org/10.1177/0305829812463655</p>

<p>Mcc. Heyman, J., 1995. Putting Power in the Anthropology of Bureaucracy: The Immigration and Naturalization Service at the Mexico-United States Border. Current Anthropology 36, 261–287. https://doi.org/10.1086/204354</p>

<p>McDonald, H. (2020, August 4). Home Office to scrap “racist algorithm” for UK visa applicants. The Guardian. https://www.theguardian.com/uk-news/2020/aug/04/home-office-to-scrap-racist-algorithm-for-uk-visa-applicants</p>

<p>Mitchell, T., 2007. Society, Economy, and the State Effect, in: Sharma, A., Gupta, A. (Eds.), The Anthropology of the State: A Reader. Blackwell Publishing Ltd., pp. 172–186.</p>

<p>Murphy, E., Maguire, M., 2015. Speed, Time and Security: Anthropological Perspectives on Automated Border Control. Etnofoor 27, 157–177.</p>

<p>Tuckett, A., 2015. Strategies of Navigation: Migrants’ Everyday Encounters with Italian Immigration Bureaucracy. The Cambridge Journal of Anthropology 33, 113–128. https://doi.org/10.3167/ca.2015.330109</p>

<p>Warrel, H. (2020, August 4). Home Office drops ‘biased’ visa algorithm. Financial Times. https://www.ft.com/content/a02c6c42-95b1-419c-a798-0418011d2018</p>

<p>We won! Home Office to stop using racist visa algorithm. (2020). The Joint Council for the Welfare of Immigrants. https://www.jcwi.org.uk/News/we-won-home-office-to-stop-using-racist-visa-algorithm</p>


