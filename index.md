<h1>THE BIASES OF THE UK VISA ISSUING SYSTEM: A QUALITATIVE AND QUANTITATIVE ANALYSIS</h1>

<h2> Final project - Decoding Biases in Artificial Intelligence - SciencesPo Paris 2021-2022</h2>

<h3>Group members</h3>
<BODY> FLAMANT.M, GENELETTI.G, MANGADA REAL DE ASUA.E, PAXTON.G, VIVENOT.B

 <h3>Table of contents</h3>
 
<ol>
 <li>Introduction</li>
 <li>Literature review and approach</li>
 <li>Policy development and algorithm's deployment</li>
 <li>Methodology</li>
 <li>Scope and conclusions</li>
 <li>Bibliography</li>
 </ol>

<h2>Introduction</h2>

<BODY><p align="justify">When the news broke that the British government had been deploying a racist algorithm in order to ratify visa applications, thereby discriminating against people from the Global South, the surprise was measured. Indeed, the happening fell within a long history of exclusionary migration policy, that has favoured a certain ideal, cosmopolitan type of ‘migrant’ in contrast to the economic, low-skilled migrant constructed as undeserving. Since the London attacks of 2005 the UK has increasingly securitised its borders in both a digital and analogue form. This culminated in the <strong>"UK Home Office hostile environment policy"</strong> of 2012, charged by the UNHCR as having "fostered xenophobia within the UK” (Bulman, 2019). Commonly, this was expressed in a hidden form, with policies exploiting structural identifiers. In 2015, in light of the migrant crisis, the UK introduced <strong>a points based system</strong> (HM Government, 2020) that translated into an algorithm, hardening an already present bias and unquestioningly perpetuating the current politics of the UK government. In light of this development, we consider an investigation into the specific workings of the algorithms to be paramount. In the following, we therefore specify the bias of the algorithm in question according to nationalities and document its perpetuating effect after its deployment, initially contextualizing the role of migration policy, algorithms and their intersection in UK governance. Against this qualitative, analytic background we will quantitatively evaluate the outcomes of visa applications to the UK, both before and after implementing the algorithm.</p></BODY>


<h2>Literature Review and Approach</h2>

<BODY><p align="justify">Migration policies are generally intended to retain the integrity of a national political body (Asad, 2003; Mavelli, 2013), defining migrants as either deserving of legal status or not, in accordance to how they prop up the nation (Bosworth, 2008). In a European (Asad, 2003; Mavelli, 2013) and UK (Capdevila and Callaghan, 2008) context, migrants are therefore often considered to be either dangerous “Others” against which the nation defines itself, or an economically exploitable resource (with the exception of refugees). Thus, they succumb to particularly harsh policies (Bove et al., 2021; Ceccorulli, 2019), which use migrants’ precarity for cheap labour, perpetuating global inequalities (de León, 2015; Garza, 2018; Mcc. Heyman, 1995). This occurs despite an interest in being meritocratic, rendering this approach crucial for understanding the broader ethics encoded in UK migration policy.</p>
 
<p align="justify">The use of statistical tools such as algorithms in policy has been documented to <strong>depoliticize and perpetuate these ethics</strong>, by switching the epistemology of government from a potentially political decision to an objective, calculated one (Amoore and Piotukh, 2015; Anders, 2008; Gilbert, 2020). Moreover, algorithms already have a long history of being unsuccessfully deployed at borders in different formats, however literature on algorithms in visa-decision processes remains sparse (Amoore, 2006; Anderson, 2014; Murphy and Maguire, 2015). Here, there is a great emphasis on how the presence of a ranking or predictive device (which can be an algorithm) are discriminatory, easily evaded, and ultimately inaccurate. The existence of a technologically securitized border still determines legality and shapes lives. Our investigation builds upon this work, approaching the perpetuative effect of the algorithm valuing visa decisions to the UK. This is <strong>not to say the deployment of algorithms in visa granting systems is inherently bad</strong>, indeed they are not the only black box present. Government institutions retain an opacity and unpredictability, which is exacerbated due to their inherent status of power (Mitchell, 2007; Tuckett, 2015). This may be actually rendered more tangible through an algorithm. It is from this nuanced perspective of critique and appreciation for the complex situation at hand, that we seek to <strong>decode the bias of the UK visa granting algorithm in an attempt to offer adequate solutions</strong>.</p>

 
<h2>Policy Development and Algorithm's Deployment</h2>

<BODY> <p align="justify">The dynamics outlined above have indeed been observed in the UK immigration system. Since 2015, the UK has filtered visa applications through <strong>an algorithm based on a traffic light system that assigned a red, amber or green risk level to each applicant</strong>. A joint investigation in 2017 between the tech-justice group <strong>FoxGlove</strong> (2020) and the <strong>Joint Council for the Welfare of Immigrants</strong> (2020) claimed that it discriminated against certain nationalities. The precise functioning of the algorithm had never been released by the Home Office as under Section 31st of the Freedom Information Act information on immigration controls does not have to be disclosed. Despite this, following investigation the Home Office admitted that nationality was indeed a factor that partly determined the allocation of applicants to a specific risk level, thus playing a major role in shaping the outcome of a visa application. Assignment to <strong>the ‘red’ category greatly reduced both the prior prospects of a successful application and significantly increased the duration of the visa processing</strong>. According to the investigation, this portrayed <strong>an institutionally racist structure</strong>, which had been extended by the algorithm as it used visa decision rates prior to 2015 would be used to decide which nationalities would be linked to higher (red) risk levels. This <strong>allegedly negatively affected African applicants</strong> (See also: McDonald, 2020; Lomas, 2020; Warrel, 2020; Heaven, 2020).</p>
 
<p align="justify">FoxGlove and the JCWI requested <strong>a judicial review</strong> of the Home Office’s algorithm, arguing that it violated the UK’s Equality Act of 2010. They requested the public release of the details of the predictive mechanisms and the abandonment of the system. However, <strong>litigation is still ongoing</strong>. On August 4th 2020, British authorities announced that the algorithm would be abandoned, and <strong>a redesigned system</strong> would be put in place by October of the same year. The Home Office thereby still rejected the accusation of a racial bias, however assured the public that such concerns would be considered when designing both the interim and definite new systems, focusing them on person-centric factors, excluding nationality as a sorting criteria. Today, the functioning and the predictive features of this definite new system <strong>remain undisclosed</strong>, and there is no available data on the impacts that it is having on the processing and outcomes of visa applications. As such, the UK government has been exploiting the legal ambiguity of both not acknowledging an ingrained racial bias, as well as pledging to change in order to not disclose the precise workings of the algorithm aiding the visa decision process. However, the UK government was obliged to release certain data on past visa decisions (GOV.UK, 2021b). <strong>We make use of the available data in order to approximate the workings of the algorithm, which were never disclosed, nearing a more comprehensive understanding of the synergies between algorithms and migration policy</strong>.</p>
 
<h2>Methodology and Findings</h2>
 
<p align="justify">Due to the Home Office’s opaque policies and the lack of a judicial decision, <strong>our quantitative analysis could not rely on certain data</strong>. First, whilst aware that nationality was relevant to the risk scale, <strong>the specific risk-scales attributed to applicants remained unreleased</strong>. Second, the Home Office did not publish <strong>information on the resolution times of applications</strong>, inhibiting us form evaluating potential discrimination in this dimension. Third, <strong>the functioning of the algorithm’s balck box and the role of its predictions</strong> is still unknown. Our analysis could only count with the final outcomes of the applications, however we lacked any information on the specific weight that the algorithm’s predictions carried in both the risk assignment and in the final decision (and in particular, whether there were human inputs in these). And lastly, we were <strong>missing further information on the applicants that could have been relevant</strong> in determining the result of their application, such as a ethnicity, age, sex or socio-economic background.</p>
 
<p align="justify">Therefore, our analysis was limited to the scarce data available: the <strong>applicants’ nationalities</strong>, the different <strong>visa types</strong> that constitute UK migration policy as well as the <strong>categories of applicants</strong> that apply to the various visa types. Due to global socio-economic structures (outlined in the literature review) these visa types and applicant categories can be linked to nationalities. Therefore, our quantitative approach utilizes the existence of differentiations in the categorization of visa applications. We subsequently build upon these, using the politicization of international relations in order to reflect on the racist effects of the algorithm. As such this analysis is built on <strong>three main blocks</strong>: (A) first, an analysis on the origin of the applicants by region and nationality, which in itself is divided into three sub-analyses (1, 2 and 3); (B) second, an analysis on visa types for all regions; and (C) third, an analysis on applicant types for all regions.</p>
 
<p align="justify">The main statistical indicator deployed and applied to the analysis of the three main blocks is <strong>the Visa Issue Rate</strong>, meaning the percentage of Visa successfully Issued on the total number of Applicants of our clustered analysis. The quantitative data analysis was completely conducted with Python (find the code repository <a href=https://colab.research.google.com/drive/17m3v0H_3LklmyBZ_GYCnKF1yp3zmgXes>here</a>), while the data visualization was conducted on Tableau.</p>
 
 <h3>A. Analysis on the origin of the applicant (region and nationality)</h3>
 
 <p align="justify">Regarding the bias that was already recognized as such, the origin of the applicants (region and nationality), we find that the lowests percentages of visa issue rate come from countries in Africa, as shown in the graph below.</p>
<p align="center"> <img width="606" alt="Github 2" src="https://user-images.githubusercontent.com/92430113/145984415-a3941b5d-c6c2-45f3-b881-1e7e0f763d49.png"></p>
 
 <p align="justify">From here on, our analysis focused on the clustering in <strong>two time spans</strong>. The first, <strong>2005-2014</strong> corresponds to the time before the alleged discriminatory algorithm existed and the second, <strong>2015-2020</strong> to when this algorithm was used. Comparison of these two times spans allows us to draw conclusions on whether the second system was indeed discriminatory or not. As it can be read in the graph below, we find that the region that saw the biggest change between the two periods is <strong>North Africa</strong>.</p>

 <p align="center"> <img width="615" alt="Github 4" src="https://user-images.githubusercontent.com/92430113/145985143-0c7afc90-7133-4210-a4c6-147782c7164a.png"></p>
 
<p align="justify">Following this, we focus our analysis on North Africa, still comparing the data from 2005-2014 to 2015-2020. We proceed in three steps: (1) by analysing the visa issue rate per country; (2) then the visa issue rate per country; and (3) lastly the visa issue rate per applicant type.</p>
 
<h4>1) Analysis of visa issue rate per country</h4>
 
<p align="justify">Here, our analysis shows that the percentage of visas issued in North Africa <strong>lowers significantly from the data before and after the algorithm was introduced</strong>. The countries in this geographical category include: <strong>Algeria, Egypt, Libya, Mauritania, Morocco, Sudan and Tunisia</strong>. Given the data available and the possible statistical measurement applicable to them, this finding allow us to partly confirm the existance of a discrimination bias embedded in the Visa Issuing algorithm deployed in 2015 toward North African applicants. Qualitatively, we can speculate this finding by relating it to the migrant crisis of 2015, where political, economic and social instabilities in North Africa forced people to leave their home country and look for better opportunities in Europe. As a result, the UK adopted a more protectionist visa issuance policy that could indeed be recognized from our quantitative analysis.</p>
 
<p align="center"> <img width="617" alt="Github 5" src="https://user-images.githubusercontent.com/92430113/145985156-e8bbe22b-d16c-470d-b21e-ba16322e4ca8.png"></p>
 
 <h4>2) Analysis of visa issue rate per visa type</h4>
 
<p align="justify">This analysis shows that the visa types issue rates that lower the most are Visa Types that can be mostly associated with vulnerable and aid-related conditions, such as the EEA family permit, the Family and the visitors. Further information on the details and definitions of Visa Types can be found in the Appendix.</p>
 
<p align="center"> <img width="607" alt="github 6" src="https://user-images.githubusercontent.com/92430113/145985226-ff8e274c-476f-4bfb-ab1c-b9cd8f7f52ce.png"> </p>
 
 <h4>3) Analysis of visa issuance rate per applicant type</h4>
 
<p align="justify">In this part, we analysed the visa issuance rate per applicant type for North Africa, with the data still divided in the two time spans mentioned above. As a “dependent”, applicants are not claiming their own rights but will be considered as part of the application of the main applicant because of their relation. We observe that <strong>the category of dependents is the one that lowered the most</strong>. This does not allow us to draw absolute conclusions. We can make the assumption that, because dependents are very often children accompanying their parents, a decrease in the visa issuance rate for them demonstrates the UK’s intention to limit migration.</p>

<p align="center"> <img width="621" alt="Github 7" src="https://user-images.githubusercontent.com/92430113/145985240-65c2ad65-8bb5-4c5c-83a4-6cd92f5f64e6.png"> </p>
 
 <h3>B. Analysis on visa type (for all regions)</h3>
 
<p align="justify">In this second part, we analysed potential discrimination on the Visa Type, not applied to specific Regions or nationalities. As we did in our previous analysis, we have clustered our analysis of the visa types in two time spans: for the years 2005-2014 and 2015-2020. We observe that the percentages of the visa issuance rate for visa type that lowers the most are the EEA family permit and the other settlements. These results, shown in the graph below, are quite telling in showing how the UK was willing to issue visas to migrants who would “prop up the nation'' (Bosworth, 2008). Indeed, the visa issuance rate for skilled workers, temporary workers and other study increased while these rates decreased significantly for EEA family permits and other settlements, the latter categories involving no consideration of the professional or academic qualification of the applicants. </p>

<p align="center"> <img width="617" alt="Github 9" src="https://user-images.githubusercontent.com/92430113/145985267-d0d60d86-e433-47d8-a00f-c83b9dd0577a.png"></p>
 
 <h3>C. Analysis on applicant type (for all regions)</h3>
 
<p align="justify">In this third part, we follow an analysis of the Applicant Visa Issue Rate for all the years, thus <strong>without time clustering</strong>. Out of our three studies, this quantitative analysis block shows <strong>the least relevant results</strong>: the applicant type does not seem to show a strong impact on the visa issue rates. Therefore, our study cannot draw any relevant conclusions from this analysis. These inconclusive results do not change when clustering by time (2005-2014 and 2015-2020), as seen in the following graph.</p> 
 
<p align="center"> <img width="622" alt="github 11" src="https://user-images.githubusercontent.com/92430113/146191838-94786c95-f004-4ce4-8d79-2c3b4721b081.png"></p>

<h2>Scope and conclusions</h2>
 
<p align="justify">It is therefore evident from our analysis that <strong>the algorithm deployed by the UK Home office perpetuated existent racist dynamics further</strong>. More concretely, nationality played a role in informing the risk scores used to classify applicants. Our analysis shows that as a result, the UK Visa Issuing Algorithm negatively affected North African applicants more than other applicants. Indeed, North African visa applicants were disproportionately rejected before 2015. However, this increased with the introduction of the algorithm which furthered this effect, potentially both in form or through the presence of <strong>an internal feedback loop</strong>. Nevertheless, contrary to what was initially alleged, <strong>the bias did not seem to discriminate against Sub-Saharan African applicants</strong>.</p>

<p align="justify">Probing further, <strong>the Visa Types that were most affected</strong> by a decrease of the Visa Issue Rate in North Africa before and after 2015 were <strong>those linked to a higher level of vulnerability and need of [humanitarian] assistance</strong>, whilst a tendency that was more broadly identifiable. Moreover, the Applicant Type that was most affected by a decrease of the Visa Issue Rate in North Africa before and after 2015 was the Dependent type. Both these findings further emphasise <strong>the prioritization of economic profitability</strong> in disregard for the potential sociality ensuing migration, long since an exploitative cornerstone of migration policy.  The question remains, considering the algorithm is a perpetuation of exclusionary dynamics of the nation-state beyond a reiteration of biases in data, what a fair and realistic deployment of algorithms at borders would look like. In other words an algorithm which genuinely addresses contemporary socio-economic tensions, to political and real world effect.</p>
 
<h2>Appendix</h2>
 
<h3>Visa types</h3>
 
 <ul>
  <li type="disc"> <p align="justify"> <p align="justify"><strong>Visitors visas</strong>: Visitors are people who wish to stay in the UK for a temporary period of less than six months.</p> </li> 
   
<li type="disc"> <p align="justify">  <strong>Sponsored study visas</strong>: meant for students who have been offered a place on a course by a licensed student sponsored and wish therefore to study under this program in the UK.</p> </li> 
 
 <li type="disc"> <p align="justify">  <strong>Other study visas</strong>: granted when someone wishes to study in the UK in another framework than the sponsored one.</p> </li> 
 
 <li type="disc"> <p align="justify">  <strong>Skilled workers visas</strong>: a special category of visas among work visas, meant for workers who have been offered a skilled job with an annual salary of at least £25,000.</p> </li> 
 
 <li type="disc"> <p align="justify">  <strong>High value visas</strong>: they follow the same logic as Skilled worker visas but are meant for high-value individuals who will contribute to growth and productivity.</p> </li> 
 
  <li type="disc"> <p align="justify">  <strong>Other work visas</strong>: work visas that do not fit in the framework of the skilled workers or high-value visas.</p> </li> 
  
  <li type="disc"> <p align="justify">  <strong>Family visas</strong>: they allow people to apply for a visa based on their family connection with someone in the UK, whether this person is a UK citizen or has just been granted a visa to stay.</p> </li> 
  
  <li type="disc"> <p align="justify">  <strong>Temporary workers visas</strong>: granted when someone needs to visit the UK for a short period of time to work.</p> </li> 
  
  <li type="disc"> <p align="justify">  <strong>Other temporary visas</strong>:  similar to the above but are meant for applicants who do not fit in the framework of the temporary visas.</p> </li> 
  
  <li type="disc"> <p align="justify">  <strong>Dependant visas</strong>:  granted to people who apply on the basis of their relationship to another applicant, whether they are joining or accompanying the latest.</p> </li> 
  
  <li type="disc"> <p align="justify">  <strong>EEA family permit</strong>: allows a non-EEA citizen to enter into the UK on the basis of his/ her relationship to an EEA citizen.</p> </li> 
  
   <li type="disc"> <p align="justify">  <strong>EU Settlement Scheme family permit</strong>:  launched following the UK’s decision to leave the EU and has existed since March 30th 2019. It allows a dependent to join, or accompany, an EEA citizen who has been granted indefinite or limited leave under the EU Settlement Scheme. Data relating to this type of visa was included in the dataset but will not be analysed in our study because of the recency of the data.</p> </li> 
   
   <li type="disc">  <p align="justify"> <strong>Other settlement visas</strong>: refer to visas that can allow for indefinite leave to enter (on arrival) or indefinite leave to remain (after entry).</p> </li> 
 
<h3>Data cleaning and manipulation</h3>
 
  <ul>
  <li type="disc"> <p align="justify">The following variables were cancelled from the original dataset: "Quarter", "Nationality", "Visa type group", "Visa type subgroup".</p> </li> 
   
<li type="disc">  <p align="justify"> For matters of uniformity and comfort, the variables names were changes to: ['Year', 'Nationality', 'Region', 'Visa type', 'Applicant type', 'Case outcome', 'Decisions'].</p> </li> 
   
  <li type="disc"> <p align="justify"> We only kept data regarding the case outcomes “Issued” and “Refused”. The original dataset contained values also for “Withdrawn” and “Lapsed” applications, which were not relevant to our analysis and that we thus were not considered.</p> </li>
   
 <li type="disc"> <p align="justify"> We transformed the data type of the variables "Year" and “Decisions” into integers (they originally came as floats).</p></li> 
  </ul>
 
<h2>Bibliography</h2>
 
<p align="justify">Amoore, L., 2006. Biometric borders: Governing mobilities in the war on terror. Political Geography 25, 336–351. https://doi.org/10.1016/j.polgeo.2006.02.001.</p>

<p align="justify">Amoore, L., Piotukh, V., 2015. Life Beyond Big Data: Governing with Little Analytics. Economy and Society 44, 341–366. https://doi.org/10.1080/03085147.2015.1043793.</p>

<p align="justify">Anders, G., 2008. The Normativity of Numbers: World bank and IMF Conditionality. Political and Legal Anthropology Review 31, 187–202.https://doi.org/10.1111/j.1555-2934.2008.00021.x.</p>

<p align="justify">Anderson, R., 2014. Illegality, Inc.: Clandestine Migration and the Business of Bordering Europe. University of California Press.https://doi.org/10.1093/he/9780199601660.003.0011.</p>

<p align="justify">Asad, T., 2003. What Might an Anthropology of Secularism Look Like?, in: Formations of the Secular: Christianity, Islam, Modernity. Stanford University Press, Stanford, California, pp. 21–66.</p>

<p align="justify">Bosworth, M., 2008. Border control and the limits of the Sovereign State. Social and Legal Studies 17, 199–215. https://doi.org/10.1177/0964663908089611.</p>

<p align="justify">Bove, V., Böhmelt, T., Nussio, E., 2021. Terrorism Abroad and Migration Policies at Home. Journal of European Public Policy 28, 190–207. https://doi.org/10.1080/13501763.2020.1729227.</p>

<p align="justify">Capdevila, R., Callaghan, J.E.M., 2008. ‘It’s not Racist. It’s Common Sense’. A Critical Analysis of Political Discourse Around Asylum and Immigration in the UK. Journal of Community and Applied Social Psychology 1–16. https://doi.org/10.1002/casp.</p>

<p align="justify">Ceccorulli, M., 2019. Back to Schengen: the collective securitisation of the EU free-border area. West European Politics 42, 302–322. https://doi.org/10.1080/01402382.2018.1510196.</p>

<p align="justify">Bulman, M. (2019, June 5). Austerity measures and hostile environment ‘entrenching racism’ in UK, says UN. The Independent. https://www.independent.co.uk/news/uk/home-news/austerity-racism-hostile-environment-xenophobia-un-report-rapporteur-immigration-bame-a8959866.html.</p>

<p align="justify">De León, J., 2015. The Land of Open Graves: Living and Dying on the Migrant Trail, City & Society. University of California Press, Oakland, California.</p>

<p align="justify">Garza, A.G., 2018. The temporality of illegality. Focaal 2018, 86–98. https://doi.org/10.3167/fcl.2018.810107.</p>

<p align="justify">Gilbert, P.R., 2020. Speculating on sovereignty: ‘money mining’ and corporate foreign policy at the extractive industry frontier. Economy and Society 49, 16–44. https://doi.org/10.1080/03085147.2019.1690255.</p>

<p align="justify">GOV.UK. (2021a). Browse: Work in the UK. https://www.gov.uk/browse/visas-immigration/work-visas.</p>

<p align="justify">GOV.UK. (2021b). Managed migration datasets.https://www.gov.uk/government/statistical-data-sets/managed-migration-datasets.</p>

<p align="justify">Heaven, W. D. (2020, August 5). The UK is dropping an immigration algorithm that critics say is racist. MIT Technology Review.https://www.technologyreview.com/2020/08/05/1006034/the-uk-is-dropping-an-immigration-algorithm-that-critics-say-is-racist/.</p>

<p align="justify">HM Government, 2020. The UK’s Points-Based Immigration System: Further Details.</p>
 
<p align="justify">Home Office says it will abandon its racist visa algorithm – after we sued them. (2020, August 4). Foxglove. https://www.foxglove.org.uk/2020/08/04/home-office-says-it-will-abandon-its-racist-visa-algorithm-after-we-sued-them/.</p>

<p align="justify">Lomas, N. (2020, August 4). UK commits to redesign visa streaming algorithm after challenge to “racist” tool. TechCrunch. https://techcrunch.com/2020/08/04/uk-commits-to-redesign-visa-streaming-algorithm-after-challenge-to-racist-tool/?guccounter=1.</p>

<p align="justify">Mavelli, L., 2013. Between Normalisation and Exception: The Securitisation of Islam and the Construction of the Secular Subject. Millennium: Journal of International Studies 41, 159–181. https://doi.org/10.1177/0305829812463655.</p>

<p align="justify">Mcc. Heyman, J., 1995. Putting Power in the Anthropology of Bureaucracy: The Immigration and Naturalization Service at the Mexico-United States Border. Current Anthropology 36, 261–287. https://doi.org/10.1086/204354.</p>

<p align="justify">McDonald, H. (2020, August 4). Home Office to scrap “racist algorithm” for UK visa applicants. The Guardian. https://www.theguardian.com/uk-news/2020/aug/04/home-office-to-scrap-racist-algorithm-for-uk-visa-applicants.</p>

<p align="justify">Mitchell, T., 2007. Society, Economy, and the State Effect, in: Sharma, A., Gupta, A. (Eds.), The Anthropology of the State: A Reader. Blackwell Publishing Ltd., pp. 172–186.</p>

<p align="justify">Murphy, E., Maguire, M., 2015. Speed, Time and Security: Anthropological Perspectives on Automated Border Control. Etnofoor 27, 157–177.</p>

<p align="justify">Tuckett, A., 2015. Strategies of Navigation: Migrants’ Everyday Encounters with Italian Immigration Bureaucracy. The Cambridge Journal of Anthropology 33, 113–128. https://doi.org/10.3167/ca.2015.330109.</p>

<p align="justify">Warrel, H. (2020, August 4). Home Office drops ‘biased’ visa algorithm. Financial Times.https://www.ft.com/content/a02c6c42-95b1-419c-a798-0418011d2018.</p>

<p align="justify">We won! Home Office to stop using racist visa algorithm. (2020). The Joint Council for the Welfare of Immigrants. https://www.jcwi.org.uk/News/we-won-home-office-to-stop-using-racist-visa-algorithm.</p>
